{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "from trainer import Trainer\n",
    "from dataset import SpectrogramReader, Dataset, DataLoader, logger\n",
    "from dcnet import DCNet, DCNetDecoder\n",
    "from utils import nfft, parse_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uttloader(scp_config, reader_kwargs, loader_kwargs, train=True):\n",
    "    mix_reader = SpectrogramReader(scp_config['mixture'], **reader_kwargs)\n",
    "    target_reader = [\n",
    "        SpectrogramReader(scp_config[spk_key], **reader_kwargs)\n",
    "        for spk_key in scp_config if spk_key[:3] == 'spk'\n",
    "    ]\n",
    "    dataset = Dataset(mix_reader, target_reader)\n",
    "    print(dataset[12][0].shape)\n",
    "    print(dataset[12][1][0].shape)\n",
    "    print(dataset[12][1][1].shape)\n",
    "    # modify shuffle status\n",
    "    loader_kwargs[\"shuffle\"] = train\n",
    "    # validate perutt if needed\n",
    "    # if not train:\n",
    "    #     loader_kwargs[\"batch_size\"] = 1\n",
    "    # if validate, do not shuffle\n",
    "    utt_loader = DataLoader(dataset, **loader_kwargs)\n",
    "    return utt_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    debug = args.debug\n",
    "    logger.info(\n",
    "        \"Start training in {} model\".format('debug' if debug else 'normal'))\n",
    "    num_bins, config_dict = parse_yaml(args.config)\n",
    "    reader_conf = config_dict[\"spectrogram_reader\"]\n",
    "    loader_conf = config_dict[\"dataloader\"]\n",
    "    dcnnet_conf = config_dict[\"dcnet\"]\n",
    "\n",
    "    batch_size = loader_conf[\"batch_size\"]\n",
    "    logger.info(\n",
    "        \"Training in {}\".format(\"per utterance\" if batch_size == 1 else\n",
    "                                '{} utterance per batch'.format(batch_size)))\n",
    "\n",
    "    train_loader = uttloader(\n",
    "        config_dict[\"train_scp_conf\"]\n",
    "        if not debug else config_dict[\"debug_scp_conf\"],\n",
    "        reader_conf,\n",
    "        loader_conf,\n",
    "        train=True)\n",
    "#    valid_loader = uttloader(\n",
    "#        config_dict[\"valid_scp_conf\"]\n",
    "#        if not debug else config_dict[\"debug_scp_conf\"],\n",
    "#        reader_conf,\n",
    "#        loader_conf,\n",
    "#        train=False)\n",
    "#    checkpoint = config_dict[\"trainer\"][\"checkpoint\"]\n",
    "#    logger.info(\"Training for {} epoches -> {}...\".format(\n",
    "#        args.num_epoches, \"default checkpoint\"\n",
    "#        if checkpoint is None else checkpoint))\n",
    "\n",
    "\n",
    "    a = next(iter(train_loader))\n",
    "    print(a[0].shape)\n",
    "    print(a[1].shape)\n",
    "    print(a[2].shape)\n",
    "    dcnet = DCNet(num_bins, **dcnnet_conf)\n",
    "    dcnet_decode = DCNetDecoder(num_bins, **dcnnet_conf)\n",
    "    out = dcnet(a[0])\n",
    "    print(out.squeeze().shape)\n",
    "    decode_out = dcnet_decode(out.squeeze())\n",
    "#     print(out.shape)\n",
    "    print(\"decoder output\", decode_out-a[0])\n",
    "#     trainer = Trainer(dcnet, **config_dict[\"trainer\"])\n",
    "#     trainer.run(train_loader, valid_loader, num_epoches=args.num_epoches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-01-23 15:44:30,871 [<ipython-input-3-920bdb836dec>:4 - INFO ] Start training in debug model\n",
      "2020-01-23 15:44:30,881 [<ipython-input-3-920bdb836dec>:13 - INFO ] Training in per utterance\n",
      "2020-01-23 15:44:30,887 [/home/ubuntu/deep-clustering/dataset.py:40 - INFO ] Create SpectrogramReader for ./data/2spk/test/wav8k_min_mix.scp with 3000 utterances\n",
      "2020-01-23 15:44:30,893 [/home/ubuntu/deep-clustering/dataset.py:40 - INFO ] Create SpectrogramReader for ./data/2spk/test/wav8k_min_s1.scp with 3000 utterances\n",
      "2020-01-23 15:44:30,899 [/home/ubuntu/deep-clustering/dataset.py:40 - INFO ] Create SpectrogramReader for ./data/2spk/test/wav8k_min_s2.scp with 3000 utterances\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(706, 129)\n",
      "(706, 129)\n",
      "(706, 129)\n",
      "torch.Size([658, 129])\n",
      "torch.Size([658, 129])\n",
      "torch.Size([658, 129])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:1339: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([84882, 20])\n",
      "decoder output tensor([[1.8381, 2.3416, 4.0811,  ..., 7.1844, 6.7106, 6.5764],\n",
      "        [2.1981, 2.7783, 4.7065,  ..., 5.7026, 5.9964, 6.2000],\n",
      "        [2.9323, 3.2905, 6.9986,  ..., 4.5831, 4.8302, 4.9681],\n",
      "        ...,\n",
      "        [2.0774, 1.8685, 1.8357,  ..., 5.2650, 4.8654, 5.0637],\n",
      "        [5.0002, 3.1249, 3.1457,  ..., 5.0672, 4.7459, 5.1371],\n",
      "        [3.1505, 3.3748, 5.2880,  ..., 5.5818, 4.4799, 4.3835]],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    config = \"conf/train.yaml\"\n",
    "    debug = True\n",
    "    num_epoches = 20\n",
    "# args ={\"config\":\"conf/train.yaml\", \"debug\":False, \"num_epoches\":20} \n",
    "# print(args[\"debug\"])\n",
    "train(Args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.zeros((24,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24])\n"
     ]
    }
   ],
   "source": [
    "a = a.unsqueeze(dim=0)\n",
    "print(a.shape)\n",
    "a = a.view(-1, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
