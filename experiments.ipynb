{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from trainer import Trainer\n",
    "from dataset import SpectrogramReader, Dataset, DataLoader, logger\n",
    "from dcnet import DCNet, DCNetDecoder\n",
    "from utils import nfft, parse_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export WANDB_NOTEBOOK_NAME=experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/kantologist/Speaker+Separation\" target=\"_blank\">https://app.wandb.ai/kantologist/Speaker+Separation</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/kantologist/Speaker+Separation/runs/etidnz00\" target=\"_blank\">https://app.wandb.ai/kantologist/Speaker+Separation/runs/etidnz00</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
     ]
    }
   ],
   "source": [
    "# Weight and Bias configuration\n",
    "\n",
    "run = wandb.init(project=\"Speaker Separation\")\n",
    "wandb_config = run.config\n",
    "wandb_config.num_epoches = 1\n",
    "wandb_config.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uttloader(scp_config, reader_kwargs, loader_kwargs, train=True):\n",
    "    mix_reader = SpectrogramReader(scp_config['mixture'], **reader_kwargs)\n",
    "    target_reader = [\n",
    "        SpectrogramReader(scp_config[spk_key], **reader_kwargs)\n",
    "        for spk_key in scp_config if spk_key[:3] == 'spk'\n",
    "    ]\n",
    "    dataset = Dataset(mix_reader, target_reader)\n",
    "#     print(dataset[12][0].shape)\n",
    "#     print(dataset[12][1][0].shape)\n",
    "#     print(dataset[12][1][1].shape)\n",
    "    # modify shuffle status\n",
    "    loader_kwargs[\"shuffle\"] = train\n",
    "    # validate perutt if needed\n",
    "    # if not train:\n",
    "    #     loader_kwargs[\"batch_size\"] = 1\n",
    "    # if validate, do not shuffle\n",
    "    utt_loader = DataLoader(dataset, **loader_kwargs)\n",
    "    return utt_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd() + '/weights/'\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "def loss(x, x_):\n",
    "    loss_ = loss_fn(x, x_)\n",
    "    return loss_\n",
    "\n",
    "def optimizer(encoder, decoder):\n",
    "    optimizer_ = torch.optim.AdamW(list(encoder.parameters()) + list(decoder.parameters()), lr=wandb_config.lr)\n",
    "    return optimizer_\n",
    "\n",
    "def train(args):\n",
    "    debug = args.debug\n",
    "    logger.info(\n",
    "        \"Start training in {} model\".format('debug' if debug else 'normal'))\n",
    "    num_bins, config_dict = parse_yaml(args.config)\n",
    "    reader_conf = config_dict[\"spectrogram_reader\"]\n",
    "    loader_conf = config_dict[\"dataloader\"]\n",
    "    dcnnet_conf = config_dict[\"dcnet\"]\n",
    "\n",
    "    batch_size = loader_conf[\"batch_size\"]\n",
    "    logger.info(\n",
    "        \"Training in {}\".format(\"per utterance\" if batch_size == 1 else\n",
    "                                '{} utterance per batch'.format(batch_size)))\n",
    "\n",
    "    train_loader = uttloader(\n",
    "        config_dict[\"train_scp_conf\"]\n",
    "        if not debug else config_dict[\"debug_scp_conf\"],\n",
    "        reader_conf,\n",
    "        loader_conf,\n",
    "        train=True)\n",
    "#    valid_loader = uttloader(\n",
    "#        config_dict[\"valid_scp_conf\"]\n",
    "#        if not debug else config_dict[\"debug_scp_conf\"],\n",
    "#        reader_conf,\n",
    "#        loader_conf,\n",
    "#        train=False)\n",
    "#    checkpoint = config_dict[\"trainer\"][\"checkpoint\"]\n",
    "#    logger.info(\"Training for {} epoches -> {}...\".format(\n",
    "#        args.num_epoches, \"default checkpoint\"\n",
    "#        if checkpoint is None else checkpoint))\n",
    "#     loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "    dcnet = DCNet(num_bins, **dcnnet_conf)\n",
    "    dcnet_decode = DCNetDecoder(num_bins, **dcnnet_conf)\n",
    "    optimizer_ = optimizer(dcnet, dcnet_decode)\n",
    "\n",
    "    for epoch in range(args.num_epoches):\n",
    "        for i in range(3):\n",
    "            for a in iter(train_loader):\n",
    "                if i != 0:\n",
    "                    input_ = torch.mul(a[i].float(),a[0])\n",
    "                else:\n",
    "                    input_ = a[i]\n",
    "    #             print(\"Input\", input_)\n",
    "                out = dcnet(input_)\n",
    "#                 print(out.squeeze().shape)\n",
    "                decode_out = dcnet_decode(out.squeeze())\n",
    "                optimizer_.zero_grad()\n",
    "                loss_ = loss(input_, decode_out)\n",
    "                wandb.log({'epoch': epoch, 'Speaker '+ str(i) + ' loss': loss_})\n",
    "#                 print(\"Loss\", loss_.item())\n",
    "                loss_.backward()\n",
    "                optimizer_.step()\n",
    "\n",
    "                decode_out = torch.sigmoid(decode_out)\n",
    "#                 print(\"decoder output\", decode_out)\n",
    "    torch.save(dcnet.state_dict(), PATH + \"encoder_\" + str(i))\n",
    "    torch.save(dcnet_decode.state_dict(), PATH + \"decoder_\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-06 13:52:59,292 [<ipython-input-25-d18d4d514533>:14 - INFO ] Start training in debug model\n",
      "2020-02-06 13:52:59,300 [<ipython-input-25-d18d4d514533>:23 - INFO ] Training in per utterance\n",
      "2020-02-06 13:52:59,304 [/home/ubuntu/deep-clustering/dataset.py:40 - INFO ] Create SpectrogramReader for ./data/2spk/test/wav8k_min_mix.scp with 3000 utterances\n",
      "2020-02-06 13:52:59,308 [/home/ubuntu/deep-clustering/dataset.py:40 - INFO ] Create SpectrogramReader for ./data/2spk/test/wav8k_min_s1.scp with 3000 utterances\n",
      "2020-02-06 13:52:59,312 [/home/ubuntu/deep-clustering/dataset.py:40 - INFO ] Create SpectrogramReader for ./data/2spk/test/wav8k_min_s2.scp with 3000 utterances\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:1339: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([77787, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/functional.py:1339: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67983, 20])\n",
      "torch.Size([99330, 20])\n",
      "torch.Size([100233, 20])\n",
      "torch.Size([66306, 20])\n",
      "torch.Size([90945, 20])\n",
      "torch.Size([88107, 20])\n",
      "torch.Size([79206, 20])\n",
      "torch.Size([79722, 20])\n",
      "torch.Size([77916, 20])\n",
      "torch.Size([77271, 20])\n",
      "torch.Size([146544, 20])\n",
      "torch.Size([72369, 20])\n",
      "torch.Size([99201, 20])\n",
      "torch.Size([84108, 20])\n",
      "torch.Size([132483, 20])\n",
      "torch.Size([54696, 20])\n",
      "torch.Size([73401, 20])\n",
      "torch.Size([87333, 20])\n",
      "torch.Size([71982, 20])\n",
      "torch.Size([89139, 20])\n",
      "torch.Size([87720, 20])\n",
      "torch.Size([84108, 20])\n",
      "torch.Size([90816, 20])\n",
      "torch.Size([78174, 20])\n",
      "torch.Size([102297, 20])\n",
      "torch.Size([60888, 20])\n",
      "torch.Size([89784, 20])\n",
      "torch.Size([78948, 20])\n",
      "torch.Size([88365, 20])\n",
      "torch.Size([143706, 20])\n",
      "torch.Size([89913, 20])\n",
      "torch.Size([111456, 20])\n",
      "torch.Size([81786, 20])\n",
      "torch.Size([93267, 20])\n",
      "torch.Size([161379, 20])\n",
      "torch.Size([93654, 20])\n",
      "torch.Size([92880, 20])\n",
      "torch.Size([100233, 20])\n",
      "torch.Size([44892, 20])\n",
      "torch.Size([45279, 20])\n",
      "torch.Size([93396, 20])\n",
      "torch.Size([88881, 20])\n",
      "torch.Size([57921, 20])\n",
      "torch.Size([84753, 20])\n",
      "torch.Size([81012, 20])\n",
      "torch.Size([145254, 20])\n",
      "torch.Size([84753, 20])\n",
      "torch.Size([99975, 20])\n",
      "torch.Size([144222, 20])\n",
      "torch.Size([136998, 20])\n",
      "torch.Size([150027, 20])\n",
      "torch.Size([45150, 20])\n",
      "torch.Size([87720, 20])\n",
      "torch.Size([102942, 20])\n",
      "torch.Size([88623, 20])\n",
      "torch.Size([63597, 20])\n",
      "torch.Size([77529, 20])\n",
      "torch.Size([98427, 20])\n",
      "torch.Size([43473, 20])\n",
      "torch.Size([131709, 20])\n",
      "torch.Size([101136, 20])\n",
      "torch.Size([73917, 20])\n",
      "torch.Size([96105, 20])\n",
      "torch.Size([85140, 20])\n",
      "torch.Size([50181, 20])\n",
      "torch.Size([129516, 20])\n",
      "torch.Size([97137, 20])\n",
      "torch.Size([65532, 20])\n",
      "torch.Size([116745, 20])\n",
      "torch.Size([119970, 20])\n",
      "torch.Size([94170, 20])\n",
      "torch.Size([82947, 20])\n",
      "torch.Size([56244, 20])\n",
      "torch.Size([86688, 20])\n",
      "torch.Size([148350, 20])\n",
      "torch.Size([63597, 20])\n",
      "torch.Size([87075, 20])\n",
      "torch.Size([88881, 20])\n",
      "torch.Size([114681, 20])\n",
      "torch.Size([88623, 20])\n",
      "torch.Size([167958, 20])\n",
      "torch.Size([124743, 20])\n",
      "torch.Size([144480, 20])\n",
      "torch.Size([96363, 20])\n",
      "torch.Size([156864, 20])\n",
      "torch.Size([48117, 20])\n",
      "torch.Size([73530, 20])\n",
      "torch.Size([75981, 20])\n",
      "torch.Size([82560, 20])\n",
      "torch.Size([41022, 20])\n",
      "torch.Size([115971, 20])\n",
      "torch.Size([100878, 20])\n",
      "torch.Size([98556, 20])\n",
      "torch.Size([92493, 20])\n",
      "torch.Size([100362, 20])\n",
      "torch.Size([33024, 20])\n",
      "torch.Size([149898, 20])\n",
      "torch.Size([141513, 20])\n",
      "torch.Size([74304, 20])\n",
      "torch.Size([159186, 20])\n",
      "torch.Size([74949, 20])\n",
      "torch.Size([81270, 20])\n",
      "torch.Size([157509, 20])\n",
      "torch.Size([88236, 20])\n",
      "torch.Size([96105, 20])\n",
      "torch.Size([87075, 20])\n",
      "torch.Size([89913, 20])\n",
      "torch.Size([92493, 20])\n",
      "torch.Size([176859, 20])\n",
      "torch.Size([122808, 20])\n",
      "torch.Size([105522, 20])\n",
      "torch.Size([34701, 20])\n",
      "torch.Size([86688, 20])\n",
      "torch.Size([90816, 20])\n",
      "torch.Size([102813, 20])\n",
      "torch.Size([72111, 20])\n",
      "torch.Size([81786, 20])\n",
      "torch.Size([61275, 20])\n",
      "torch.Size([98556, 20])\n",
      "torch.Size([94299, 20])\n",
      "torch.Size([75336, 20])\n",
      "torch.Size([141513, 20])\n",
      "torch.Size([75723, 20])\n",
      "torch.Size([108618, 20])\n",
      "torch.Size([101781, 20])\n",
      "torch.Size([120873, 20])\n",
      "torch.Size([117648, 20])\n",
      "torch.Size([104490, 20])\n",
      "torch.Size([122163, 20])\n",
      "torch.Size([112230, 20])\n",
      "torch.Size([111069, 20])\n",
      "torch.Size([54954, 20])\n",
      "torch.Size([94686, 20])\n",
      "torch.Size([132225, 20])\n",
      "torch.Size([68370, 20])\n",
      "torch.Size([82689, 20])\n",
      "torch.Size([74562, 20])\n",
      "torch.Size([160218, 20])\n",
      "torch.Size([98427, 20])\n",
      "torch.Size([131064, 20])\n",
      "torch.Size([48246, 20])\n",
      "torch.Size([153768, 20])\n",
      "torch.Size([74304, 20])\n",
      "torch.Size([175827, 20])\n",
      "torch.Size([82947, 20])\n",
      "torch.Size([146931, 20])\n",
      "torch.Size([46956, 20])\n",
      "torch.Size([80496, 20])\n",
      "torch.Size([124614, 20])\n",
      "torch.Size([72369, 20])\n",
      "torch.Size([52116, 20])\n",
      "torch.Size([101007, 20])\n",
      "torch.Size([77271, 20])\n",
      "torch.Size([66693, 20])\n",
      "torch.Size([68499, 20])\n",
      "torch.Size([60759, 20])\n",
      "torch.Size([107586, 20])\n",
      "torch.Size([91461, 20])\n",
      "torch.Size([52374, 20])\n",
      "torch.Size([91461, 20])\n",
      "torch.Size([123711, 20])\n",
      "torch.Size([54954, 20])\n",
      "torch.Size([75981, 20])\n",
      "torch.Size([119454, 20])\n",
      "torch.Size([46053, 20])\n",
      "torch.Size([77787, 20])\n",
      "torch.Size([117132, 20])\n",
      "torch.Size([96492, 20])\n",
      "torch.Size([80238, 20])\n",
      "torch.Size([88365, 20])\n",
      "torch.Size([51858, 20])\n",
      "torch.Size([96492, 20])\n",
      "torch.Size([111198, 20])\n",
      "torch.Size([80496, 20])\n",
      "torch.Size([68886, 20])\n",
      "torch.Size([107199, 20])\n",
      "torch.Size([79593, 20])\n",
      "torch.Size([75078, 20])\n",
      "torch.Size([43344, 20])\n",
      "torch.Size([95331, 20])\n",
      "torch.Size([144996, 20])\n",
      "torch.Size([131709, 20])\n",
      "torch.Size([141126, 20])\n",
      "torch.Size([83463, 20])\n",
      "torch.Size([91719, 20])\n",
      "torch.Size([76239, 20])\n",
      "torch.Size([84753, 20])\n",
      "torch.Size([75336, 20])\n",
      "torch.Size([78948, 20])\n",
      "torch.Size([83463, 20])\n",
      "torch.Size([207432, 20])\n",
      "torch.Size([98040, 20])\n",
      "torch.Size([79464, 20])\n",
      "torch.Size([112230, 20])\n",
      "torch.Size([64242, 20])\n",
      "torch.Size([138159, 20])\n",
      "torch.Size([100878, 20])\n",
      "torch.Size([75078, 20])\n",
      "torch.Size([57921, 20])\n",
      "torch.Size([84882, 20])\n",
      "torch.Size([131451, 20])\n",
      "torch.Size([110682, 20])\n",
      "torch.Size([68370, 20])\n",
      "torch.Size([131838, 20])\n",
      "torch.Size([98040, 20])\n",
      "torch.Size([96879, 20])\n",
      "torch.Size([60888, 20])\n",
      "torch.Size([48762, 20])\n",
      "torch.Size([107457, 20])\n",
      "torch.Size([48504, 20])\n",
      "torch.Size([142287, 20])\n",
      "torch.Size([69531, 20])\n",
      "torch.Size([105264, 20])\n",
      "torch.Size([93912, 20])\n",
      "torch.Size([85527, 20])\n",
      "torch.Size([91074, 20])\n",
      "torch.Size([86688, 20])\n",
      "torch.Size([123324, 20])\n",
      "torch.Size([89784, 20])\n",
      "torch.Size([73143, 20])\n",
      "torch.Size([87075, 20])\n",
      "torch.Size([71982, 20])\n",
      "torch.Size([206400, 20])\n",
      "torch.Size([129129, 20])\n",
      "torch.Size([85914, 20])\n",
      "torch.Size([60759, 20])\n",
      "torch.Size([91848, 20])\n",
      "torch.Size([111972, 20])\n",
      "torch.Size([88752, 20])\n",
      "torch.Size([164475, 20])\n",
      "torch.Size([30573, 20])\n",
      "torch.Size([68886, 20])\n",
      "torch.Size([75981, 20])\n",
      "torch.Size([131064, 20])\n",
      "torch.Size([89526, 20])\n",
      "torch.Size([77787, 20])\n",
      "torch.Size([74046, 20])\n",
      "torch.Size([48504, 20])\n",
      "torch.Size([100233, 20])\n",
      "torch.Size([63597, 20])\n",
      "torch.Size([83592, 20])\n",
      "torch.Size([109908, 20])\n",
      "torch.Size([94815, 20])\n",
      "torch.Size([77013, 20])\n",
      "torch.Size([78819, 20])\n",
      "torch.Size([116358, 20])\n",
      "torch.Size([77787, 20])\n",
      "torch.Size([111972, 20])\n",
      "torch.Size([75207, 20])\n",
      "torch.Size([83721, 20])\n",
      "torch.Size([90171, 20])\n",
      "torch.Size([77787, 20])\n",
      "torch.Size([126033, 20])\n",
      "torch.Size([111069, 20])\n",
      "torch.Size([109650, 20])\n",
      "torch.Size([117777, 20])\n",
      "torch.Size([151188, 20])\n",
      "torch.Size([80496, 20])\n",
      "torch.Size([106812, 20])\n",
      "torch.Size([72627, 20])\n",
      "torch.Size([78819, 20])\n",
      "torch.Size([78690, 20])\n",
      "torch.Size([98556, 20])\n",
      "torch.Size([81915, 20])\n",
      "torch.Size([82173, 20])\n",
      "torch.Size([97008, 20])\n",
      "torch.Size([78819, 20])\n",
      "torch.Size([161766, 20])\n",
      "torch.Size([89139, 20])\n",
      "torch.Size([73788, 20])\n",
      "torch.Size([75465, 20])\n",
      "torch.Size([129774, 20])\n",
      "torch.Size([127194, 20])\n",
      "torch.Size([97137, 20])\n",
      "torch.Size([99459, 20])\n",
      "torch.Size([110682, 20])\n",
      "torch.Size([91461, 20])\n",
      "torch.Size([107586, 20])\n",
      "torch.Size([86817, 20])\n",
      "torch.Size([162411, 20])\n",
      "torch.Size([125130, 20])\n",
      "torch.Size([96363, 20])\n",
      "torch.Size([81399, 20])\n",
      "torch.Size([92880, 20])\n",
      "torch.Size([72369, 20])\n",
      "torch.Size([85914, 20])\n",
      "torch.Size([71337, 20])\n",
      "torch.Size([108876, 20])\n",
      "torch.Size([91074, 20])\n",
      "torch.Size([78432, 20])\n",
      "torch.Size([150156, 20])\n",
      "torch.Size([95847, 20])\n",
      "torch.Size([103329, 20])\n",
      "torch.Size([74949, 20])\n",
      "torch.Size([94686, 20])\n",
      "torch.Size([131451, 20])\n",
      "torch.Size([98427, 20])\n",
      "torch.Size([81915, 20])\n",
      "torch.Size([82173, 20])\n",
      "torch.Size([99201, 20])\n",
      "torch.Size([172860, 20])\n",
      "torch.Size([99330, 20])\n",
      "torch.Size([115068, 20])\n",
      "torch.Size([82431, 20])\n",
      "torch.Size([102684, 20])\n",
      "torch.Size([112101, 20])\n",
      "torch.Size([88107, 20])\n",
      "torch.Size([97395, 20])\n",
      "torch.Size([89526, 20])\n",
      "torch.Size([193887, 20])\n",
      "torch.Size([76497, 20])\n",
      "torch.Size([101652, 20])\n",
      "torch.Size([74046, 20])\n",
      "torch.Size([62436, 20])\n",
      "torch.Size([144480, 20])\n",
      "torch.Size([83979, 20])\n",
      "torch.Size([145899, 20])\n",
      "torch.Size([62436, 20])\n",
      "torch.Size([42441, 20])\n",
      "torch.Size([126678, 20])\n",
      "torch.Size([89655, 20])\n",
      "torch.Size([87075, 20])\n",
      "torch.Size([72369, 20])\n",
      "torch.Size([69273, 20])\n",
      "torch.Size([84624, 20])\n",
      "torch.Size([87978, 20])\n",
      "torch.Size([92106, 20])\n",
      "torch.Size([54438, 20])\n",
      "torch.Size([168603, 20])\n",
      "torch.Size([79593, 20])\n",
      "torch.Size([54567, 20])\n",
      "torch.Size([68886, 20])\n",
      "torch.Size([79464, 20])\n",
      "torch.Size([106554, 20])\n",
      "torch.Size([92364, 20])\n",
      "torch.Size([94170, 20])\n",
      "torch.Size([118293, 20])\n",
      "torch.Size([108231, 20])\n",
      "torch.Size([151188, 20])\n",
      "torch.Size([74175, 20])\n",
      "torch.Size([86172, 20])\n",
      "torch.Size([81012, 20])\n",
      "torch.Size([129516, 20])\n",
      "torch.Size([155187, 20])\n",
      "torch.Size([60243, 20])\n",
      "torch.Size([66306, 20])\n",
      "torch.Size([94170, 20])\n",
      "torch.Size([106038, 20])\n",
      "torch.Size([100104, 20])\n",
      "torch.Size([98556, 20])\n",
      "torch.Size([81270, 20])\n",
      "torch.Size([97266, 20])\n",
      "torch.Size([94170, 20])\n",
      "torch.Size([77013, 20])\n",
      "torch.Size([80754, 20])\n",
      "torch.Size([73788, 20])\n",
      "torch.Size([84237, 20])\n",
      "torch.Size([93654, 20])\n",
      "torch.Size([75207, 20])\n",
      "torch.Size([45021, 20])\n",
      "torch.Size([96492, 20])\n",
      "torch.Size([155574, 20])\n",
      "torch.Size([92622, 20])\n",
      "torch.Size([58050, 20])\n",
      "torch.Size([65661, 20])\n",
      "torch.Size([68886, 20])\n",
      "torch.Size([48633, 20])\n",
      "torch.Size([133386, 20])\n",
      "torch.Size([88365, 20])\n",
      "torch.Size([99846, 20])\n",
      "torch.Size([46182, 20])\n",
      "torch.Size([65661, 20])\n",
      "torch.Size([35733, 20])\n",
      "torch.Size([90171, 20])\n",
      "torch.Size([66951, 20])\n",
      "torch.Size([89526, 20])\n",
      "torch.Size([118164, 20])\n",
      "torch.Size([48246, 20])\n",
      "torch.Size([117906, 20])\n",
      "torch.Size([111972, 20])\n",
      "torch.Size([33153, 20])\n",
      "torch.Size([147705, 20])\n",
      "torch.Size([64371, 20])\n",
      "torch.Size([76497, 20])\n",
      "torch.Size([112230, 20])\n",
      "torch.Size([73917, 20])\n",
      "torch.Size([114939, 20])\n",
      "torch.Size([101781, 20])\n",
      "torch.Size([82560, 20])\n",
      "torch.Size([81012, 20])\n",
      "torch.Size([100233, 20])\n",
      "torch.Size([92493, 20])\n",
      "torch.Size([93267, 20])\n",
      "torch.Size([113133, 20])\n",
      "torch.Size([100362, 20])\n",
      "torch.Size([135321, 20])\n",
      "torch.Size([50181, 20])\n",
      "torch.Size([137772, 20])\n",
      "torch.Size([135321, 20])\n",
      "torch.Size([94428, 20])\n",
      "torch.Size([63597, 20])\n",
      "torch.Size([115971, 20])\n",
      "torch.Size([91848, 20])\n",
      "torch.Size([90558, 20])\n",
      "torch.Size([135708, 20])\n",
      "torch.Size([109908, 20])\n",
      "torch.Size([139449, 20])\n",
      "torch.Size([86043, 20])\n",
      "torch.Size([69531, 20])\n",
      "torch.Size([82431, 20])\n",
      "torch.Size([72627, 20])\n",
      "torch.Size([64887, 20])\n",
      "torch.Size([145641, 20])\n",
      "torch.Size([86817, 20])\n",
      "torch.Size([70821, 20])\n",
      "torch.Size([118293, 20])\n",
      "torch.Size([87333, 20])\n",
      "torch.Size([92235, 20])\n",
      "torch.Size([96234, 20])\n",
      "torch.Size([87075, 20])\n",
      "torch.Size([88365, 20])\n",
      "torch.Size([62178, 20])\n",
      "torch.Size([94299, 20])\n",
      "torch.Size([86817, 20])\n",
      "torch.Size([107199, 20])\n",
      "torch.Size([73917, 20])\n",
      "torch.Size([82947, 20])\n",
      "torch.Size([76755, 20])\n",
      "torch.Size([70563, 20])\n",
      "torch.Size([52890, 20])\n",
      "torch.Size([103458, 20])\n",
      "torch.Size([137772, 20])\n",
      "torch.Size([81915, 20])\n",
      "torch.Size([107586, 20])\n",
      "torch.Size([30573, 20])\n",
      "torch.Size([89784, 20])\n",
      "torch.Size([183438, 20])\n",
      "torch.Size([73401, 20])\n",
      "torch.Size([62823, 20])\n",
      "torch.Size([111972, 20])\n",
      "torch.Size([81399, 20])\n",
      "torch.Size([75336, 20])\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    config = \"conf/train.yaml\"\n",
    "    debug = True\n",
    "    num_epoches = wandb_config.num_epoches\n",
    "# args ={\"config\":\"conf/train.yaml\", \"debug\":False, \"num_epoches\":20} \n",
    "# print(args[\"debug\"])\n",
    "train(Args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.zeros((24,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24])\n"
     ]
    }
   ],
   "source": [
    "a = a.unsqueeze(dim=0)\n",
    "print(a.shape)\n",
    "a = a.view(-1, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/deep-clustering/weights'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd() + '/weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
